10.12
使用ZML预训练resnet34提取图像特征并生成json和h5文件
报告使用的是诊断结论
10.16
小于1的坏词大于35%，所以坏词设置为0
10.19
坏词设为0，使用征象描述，使用yss resnet101提取特征
10.19.01
直接将图像代替原来的图像特征，将图像写入h5文件，然后将CNN网络加入到后面的网络进行端到端的训练。
10.20备份
无循环batch size为1的联合训练代码
10.20.01备份
CNN NSA LSTM作为编码器，解码器使用LSTM的联合训练代码
10.24
data数据集扩展为data、data_01、data_02三个。图像为RGBA，需要转化为RGB，像素值为0-1之间
10.28*
实验说明：使用新数据集（前两个合并）重新生成json文件以及h5文件,cap使用诊断结论,使用yss resnet101提取特征，坏词为0
提升：报告样式明显增多，语言评分波动下降，最高评分基本全被刷新
分析：可能是预处理或者是数据量的影响
10.28.01
实验说明：使用新数据集（前两个合并）重新生成json文件以及h5文件,cap使用征象描述,直接使用图像拼接训练CNN LSTM LSTM，坏词为0
10.29
实验说明：使用新数据集data(原数据集再整理)重新生成json文件以及h5文件,cap使用诊断结论词典大小628,使用yss resnet101提取特征，坏词为0
分析：对比相比原来灰度图像生成的语句样式明显增加，说明模型对三通道的脑CT数据还是比较敏感。
问题1：是生成的语句所用的语料库比之前虽然有所增加但是不多（增加使用数据集data01之后生成的句子所使用的语料库明显增加）
问题2：评分比原来低，而且也是十分不稳定。（使用两个数据集的时候还比较稳定）
11.04
data_01中最少的图像为6张最大的为200多张，特征提取有问题。重新提取特征去掉小于10张影像的数据。
预测空字符串最终解决方案：使用nsa_feats作为att进行attention的指导。nsa_feats与最终生成的sa_feats即整体编码经过相同的处理过程，
数据本质上是同分布的，同分布表达的含义却不同。
11.09
旧数据新模型再跑。黑白图像数据， yss resnet101提特征，诊断结论，0坏词。
11.10
使用report-refine作为报告文本重新生成标签 词典大小317